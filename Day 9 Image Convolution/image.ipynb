{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 10:27:58.122371: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-29 10:28:00.024597: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 765 is out of bounds for axis 0 with size 720",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Draw the top and bottom horizontal lines\u001b[39;00m\n\u001b[1;32m     54\u001b[0m matched_image[top_left[\u001b[38;5;241m1\u001b[39m], top_left[\u001b[38;5;241m0\u001b[39m]:bottom_right[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 55\u001b[0m matched_image[bottom_right[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, top_left[\u001b[38;5;241m0\u001b[39m]:bottom_right[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Draw the left and right vertical lines\u001b[39;00m\n\u001b[1;32m     58\u001b[0m matched_image[top_left[\u001b[38;5;241m1\u001b[39m]:bottom_right[\u001b[38;5;241m1\u001b[39m], top_left[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 765 is out of bounds for axis 0 with size 720"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=1)  # Load image and convert to grayscale\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)  # Convert to float32\n",
    "    image = tf.squeeze(image)  # Remove the single channel dimension\n",
    "    return image.numpy()  # Convert to NumPy array\n",
    "\n",
    "# def normalize(img):\n",
    "#     img = img - np.mean(img)\n",
    "#     img = img / np.std(img)\n",
    "#     return img\n",
    "\n",
    "# def convolve2d(image, kernel):\n",
    "#     kernel_height, kernel_width = kernel.shape\n",
    "#     image_height, image_width = image.shape\n",
    "\n",
    "#     output_height = image_height - kernel_height + 1\n",
    "#     output_width = image_width - kernel_width + 1\n",
    "#     output = np.zeros((output_height, output_width))\n",
    "\n",
    "#     for y in range(output_height):\n",
    "#         for x in range(output_width):\n",
    "#             output[y, x] = np.sum(image[y:y+kernel_height, x:x+kernel_width] * kernel)\n",
    "    \n",
    "#     return output\n",
    "\n",
    "# Load the full image and the cropped part\n",
    "full_image_path = 'full.jpg'\n",
    "cropped_part_path = 'crop.jpg'\n",
    "full_image = load_image(full_image_path)\n",
    "cropped_part = load_image(cropped_part_path)\n",
    "\n",
    "# Perform 2D convolution\n",
    "convolution_result = convolve2d(full_image, cropped_part)\n",
    "\n",
    "# Find the position of the highest value in the convolution result\n",
    "y, x = np.unravel_index(np.argmax(convolution_result), convolution_result.shape)\n",
    "\n",
    "# The top-left corner of the matching region in the full image\n",
    "top_left = (x, y)\n",
    "# The bottom-right corner of the matching region in the full image\n",
    "bottom_right = (x + cropped_part.shape[1], y + cropped_part.shape[0])\n",
    "\n",
    "# Draw a rectangle around the matched region\n",
    "matched_image = np.stack([full_image] * 3, axis=-1)  # Convert grayscale to RGB for visualization\n",
    "matched_image = matched_image.astype(np.uint8)\n",
    "\n",
    "# Draw the top and bottom horizontal lines\n",
    "matched_image[top_left[1], top_left[0]:bottom_right[0]] = [0, 255, 0]\n",
    "matched_image[bottom_right[1]-1, top_left[0]:bottom_right[0]] = [0, 255, 0]\n",
    "\n",
    "# Draw the left and right vertical lines\n",
    "matched_image[top_left[1]:bottom_right[1], top_left[0]] = [0, 255, 0]\n",
    "matched_image[top_left[1]:bottom_right[1], bottom_right[0]-1] = [0, 255, 0]\n",
    "# Show the result\n",
    "plt.subplot(121), plt.imshow(full_image, cmap='gray'), plt.title('Full Image')\n",
    "plt.subplot(122), plt.imshow(matched_image), plt.title('Detected Match')\n",
    "plt.show()\n",
    "\n",
    "# Return the position of the cropped part\n",
    "(top_left, bottom_right)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sharavanask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
